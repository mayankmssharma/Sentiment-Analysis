{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"evaluation.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"362QatWzPEuv","colab_type":"code","outputId":"6bb3f203-7b0d-4dc2-806e-64f302ad01a9","executionInfo":{"status":"ok","timestamp":1541852494036,"user_tz":-330,"elapsed":1993,"user":{"displayName":"Mayank Sharma","photoUrl":"","userId":"02640302405951026543"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"IN7SqJEWPicA","colab_type":"code","outputId":"5975a123-6f3f-4517-cbe3-b9248488481c","executionInfo":{"status":"ok","timestamp":1541852507893,"user_tz":-330,"elapsed":7580,"user":{"displayName":"Mayank Sharma","photoUrl":"","userId":"02640302405951026543"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["!ls \"/content/drive/My Drive/Colab Notebooks/evaluation/project14.h5\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["'/content/drive/My Drive/Colab Notebooks/evaluation/project14.h5'\n"],"name":"stdout"}]},{"metadata":{"id":"6bncFUyMPmD8","colab_type":"code","outputId":"8b0b8931-a888-4d76-956d-f05d1ef74f71","executionInfo":{"status":"ok","timestamp":1541852518068,"user_tz":-330,"elapsed":2291,"user":{"displayName":"Mayank Sharma","photoUrl":"","userId":"02640302405951026543"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import numpy as np \n","import pandas as pd \n","import os\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Model\n","from keras.layers import Dense, Embedding, LSTM, Input\n","from sklearn.model_selection import train_test_split\n","from keras.utils.np_utils import to_categorical\n","import re"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"b3m9Hivk-x04","colab_type":"code","colab":{}},"cell_type":"code","source":["def decode(text):\n","    text = text.encode('ascii','ignore')\n","    return text"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iYjMh8KZPpkb","colab_type":"code","outputId":"e61fdc70-e36b-4ddc-af0d-24482d71e2a8","executionInfo":{"status":"ok","timestamp":1541852523205,"user_tz":-330,"elapsed":1949,"user":{"displayName":"Mayank Sharma","photoUrl":"","userId":"02640302405951026543"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"cell_type":"code","source":["data2 = pd.read_csv('/content/drive/My Drive/Colab Notebooks/evaluation/train.csv')\n","data=data2.copy()\n","pd.set_option('display.max_colwidth',-1)\n","data.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Scene</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>{Monica} How about, youre moving!! {Rachel} Look! This is ridiculous. We should be packing you!! {Phoebe} Hey, how are you guys doing? {Rachel} Great! Monicas moving! {Monica} I am not! {Rachel} Oh really?! Then how come all your stuff is in this box?! {Phoebe} Okay, you guys. You guys I think I know whats going on here. Okay, you guys {Monica} No Phoebe I am mad! {Phoebe} Well, deep-deep-deep down! {Rachel} Yeah, Im just mad! {Phoebe} Then keep running.</td>\n","      <td>NEGATIVE</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>{Phoebe} Or we could just follow your clever jokes  any ideas?</td>\n","      <td>NEUTRAL</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>{Joey} Hey Rach! Hey, you mind if I read my comic books in here? {Rachel} Sure! Why? {Joey} Oh well, Chandler and Monica are over there and it's kinda hard to concentrate. {Rachel} What?! {Rachel} She just called and said that she was gonna be working late! {Rachel} She keeps lying to me! {Rachel} That's it! {Rachel} I'm just gonna go over there and confront them right now!</td>\n","      <td>NEGATIVE</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>{Joey} You forget how many great songs Heart had. {Chandler} Yeah. {Ross} You know, Barracuda was the first song I learned to play on the keyboard. {Chandler} So, you heard it, you repeated it, so that must mean you wrote it. {Joey} Oh, you guys, with this joke. I gotta say, I know I cracked up, but Im not even sure I got it. {Ross} What, you didnt get it? The doctor is a monkey. {Chandler} And monkeys cant write out prescriptions. {Chandler} You are not allowed to laugh at my joke. {Ross} Your joke? Well, I think the Hef would disagree, which is why he sent me a check for one hundred ah-dollars.</td>\n","      <td>NEUTRAL</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>{Chandler} Hey Joe! You wanna shoot some hoops? {Joey} Oh no, I cant go. Im practicing; I got an audition to be the host of a new game show.</td>\n","      <td>POSTIVE</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Scene  \\\n","0  {Monica} How about, youre moving!! {Rachel} Look! This is ridiculous. We should be packing you!! {Phoebe} Hey, how are you guys doing? {Rachel} Great! Monicas moving! {Monica} I am not! {Rachel} Oh really?! Then how come all your stuff is in this box?! {Phoebe} Okay, you guys. You guys I think I know whats going on here. Okay, you guys {Monica} No Phoebe I am mad! {Phoebe} Well, deep-deep-deep down! {Rachel} Yeah, Im just mad! {Phoebe} Then keep running.                                                                                                                                                      \n","1  {Phoebe} Or we could just follow your clever jokes  any ideas?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n","2  {Joey} Hey Rach! Hey, you mind if I read my comic books in here? {Rachel} Sure! Why? {Joey} Oh well, Chandler and Monica are over there and it's kinda hard to concentrate. {Rachel} What?! {Rachel} She just called and said that she was gonna be working late! {Rachel} She keeps lying to me! {Rachel} That's it! {Rachel} I'm just gonna go over there and confront them right now!                                                                                                                                                                                                                                            \n","3  {Joey} You forget how many great songs Heart had. {Chandler} Yeah. {Ross} You know, Barracuda was the first song I learned to play on the keyboard. {Chandler} So, you heard it, you repeated it, so that must mean you wrote it. {Joey} Oh, you guys, with this joke. I gotta say, I know I cracked up, but Im not even sure I got it. {Ross} What, you didnt get it? The doctor is a monkey. {Chandler} And monkeys cant write out prescriptions. {Chandler} You are not allowed to laugh at my joke. {Ross} Your joke? Well, I think the Hef would disagree, which is why he sent me a check for one hundred ah-dollars.    \n","4  {Chandler} Hey Joe! You wanna shoot some hoops? {Joey} Oh no, I cant go. Im practicing; I got an audition to be the host of a new game show.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n","\n","  Sentiment  \n","0  NEGATIVE  \n","1  NEUTRAL   \n","2  NEGATIVE  \n","3  NEUTRAL   \n","4  POSTIVE   "]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"7Y25CIItRdYG","colab_type":"code","outputId":"533fc14f-036a-4fac-d7f1-f891b952d416","executionInfo":{"status":"ok","timestamp":1541852531027,"user_tz":-330,"elapsed":1403,"user":{"displayName":"Mayank Sharma","photoUrl":"","userId":"02640302405951026543"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"cell_type":"code","source":["import tensorflow as tf\n","subsetDataFrame = data[data['Sentiment'] == 'MIXED']\n","m=subsetDataFrame.copy()\n","sub2=data[data['Sentiment'] == 'POSTIVE']\n","sub2=sub2.iloc[0:115]\n","print(len(subsetDataFrame))\n","data=data.append(m,ignore_index=True)\n","data=data.append(m,ignore_index=True)\n","data=data.append(m,ignore_index=True)\n","data=data.append(m,ignore_index=True)\n","data=data.append(sub2,ignore_index=True)\n","print(len(data))\n","label = data['Sentiment']\n","pos=0\n","neg=0\n","mixed=0\n","neutral=0\n","for i in label:\n","  if i=='POSTIVE':\n","    pos=pos+1\n","  elif i=='NEGATIVE':\n","    neg=neg+1\n","  elif i=='MIXED':\n","    mixed=mixed+1\n","  else:\n","    neutral=neutral+1\n","print(pos)\n","print(neg)\n","print(mixed)\n","print(neutral)\n","tx=data['Scene'].values\n","\n","\n","y_label=[]\n","class_names = {'POSTIVE' :0, 'NEUTRAL':1, 'NEGATIVE':2, 'MIXED':3}\n","for x in label:\n","  y_label.append(class_names[str(x)])\n","\n","y=tf.keras.utils.to_categorical(y_label,num_classes=4)\n","\n","#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)\n","#print(X_train.shape,y_train.shape)\n","#print(X_test.shape,y_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["60\n","1355\n","347\n","367\n","300\n","341\n"],"name":"stdout"}]},{"metadata":{"id":"HEpkipA7OczS","colab_type":"code","outputId":"ba7c50d8-3067-41b3-ff0f-df8d2c9dc1d4","executionInfo":{"status":"ok","timestamp":1541852542272,"user_tz":-330,"elapsed":5216,"user":{"displayName":"Mayank Sharma","photoUrl":"","userId":"02640302405951026543"}},"colab":{"base_uri":"https://localhost:8080/","height":190}},"cell_type":"code","source":["#tx=data['Scene'].values\n","print(tx[1])\n","from nltk.corpus import stopwords \n","from nltk.tokenize import word_tokenize \n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","wordnet_lemmatizer = WordNetLemmatizer()\n","  \n","stop_words = set(stopwords.words('english')) \n","tx2=[]\n","for x in tx:\n","  word_tokens = word_tokenize(x) \n","  \n","  filtered_sentence = [w for w in word_tokens if not w in stop_words] \n","  filtered_sntence=[]\n","  string=\"\"\n","  \n","  for w in word_tokens: \n","      if w not in stop_words: \n","          filtered_sentence.append(w)\n","  #data['Text'] = np.vectorize(decode)(data['Text'])        \n","  tx2.append(filtered_sentence)\n","  \n","print(tx2[0])\n","print(len(tx2))\n","#print(word_tokens) \n","#print(filtered_sentence) "],"execution_count":0,"outputs":[{"output_type":"stream","text":["{Phoebe} Or we could just follow your clever jokes  any ideas? \n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","['{', 'Monica', '}', 'How', ',', 'you\\x92re', 'moving', '!', '!', '{', 'Rachel', '}', 'Look', '!', 'This', 'ridiculous', '.', 'We', 'packing', '!', '!', '{', 'Phoebe', '}', 'Hey', ',', 'guys', '?', '{', 'Rachel', '}', 'Great', '!', 'Monica\\x92s', 'moving', '!', '{', 'Monica', '}', 'I', '!', '{', 'Rachel', '}', 'Oh', 'really', '?', '!', 'Then', 'come', 'stuff', 'box', '?', '!', '{', 'Phoebe', '}', 'Okay', ',', 'guys', '.', 'You', 'guys', 'I', 'think', 'I', 'know', 'what\\x92s', 'going', '.', 'Okay', ',', 'guys', '{', 'Monica', '}', 'No', 'Phoebe', 'I', 'mad', '!', '{', 'Phoebe', '}', 'Well', ',', 'deep-deep-deep', '!', '{', 'Rachel', '}', 'Yeah', ',', 'I\\x92m', 'mad', '!', '{', 'Phoebe', '}', 'Then', 'keep', 'running', '.', '{', 'Monica', '}', 'How', ',', 'you\\x92re', 'moving', '!', '!', '{', 'Rachel', '}', 'Look', '!', 'This', 'ridiculous', '.', 'We', 'packing', '!', '!', '{', 'Phoebe', '}', 'Hey', ',', 'guys', '?', '{', 'Rachel', '}', 'Great', '!', 'Monica\\x92s', 'moving', '!', '{', 'Monica', '}', 'I', '!', '{', 'Rachel', '}', 'Oh', 'really', '?', '!', 'Then', 'come', 'stuff', 'box', '?', '!', '{', 'Phoebe', '}', 'Okay', ',', 'guys', '.', 'You', 'guys', 'I', 'think', 'I', 'know', 'what\\x92s', 'going', '.', 'Okay', ',', 'guys', '{', 'Monica', '}', 'No', 'Phoebe', 'I', 'mad', '!', '{', 'Phoebe', '}', 'Well', ',', 'deep-deep-deep', '!', '{', 'Rachel', '}', 'Yeah', ',', 'I\\x92m', 'mad', '!', '{', 'Phoebe', '}', 'Then', 'keep', 'running', '.']\n","1355\n"],"name":"stdout"}]},{"metadata":{"id":"9_I8u2EGiz-o","colab_type":"code","outputId":"62f21ff2-7c29-4ac4-de7b-55cac8d203db","executionInfo":{"status":"ok","timestamp":1541852555782,"user_tz":-330,"elapsed":1187,"user":{"displayName":"Mayank Sharma","photoUrl":"","userId":"02640302405951026543"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"cell_type":"code","source":["from sklearn.preprocessing import Normalizer\n","\n","num_words = 6000\n","tokenizer = Tokenizer(num_words=num_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\nÂ',\n","                                   lower=True,split=' ')\n","tokenizer.fit_on_texts(tx2)\n","X = tokenizer.texts_to_sequences(tx2)\n","print(len(X))\n","\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index))\n","\n","max_length_of_text = 150\n","X =pad_sequences(X, maxlen=max_length_of_text)\n","print(len(X))\n","print(X[250])\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1355\n","Found 5792 unique tokens.\n","1355\n","[   8    2   91    4   43  170   33    1   97  402    2  160   77  645\n","    3    6  452  109 2155 3875  391  115 3876    7    1    8    2  348\n","    7    5    1   97  402    2   25    3   15  489  257    4    1   97\n","  402    2    6  144  180  175 3877  364  195   19    6   27  151  545\n","   62    4    1   97  402    2   33  343    4    1   97  402    2 3878\n","   79    7    1    8    2   33    6 1998    4    1   97  402    2  419\n"," 3879   27    4   21   53 2748 2749    4    1    8    2   21   53   42\n","  139    4    1   97  402    2  343    3  312   15   79  115   67    4\n","   50 1408  322    3   15  121  695  383    4    1    8    2   14  111\n","    4  133   63   42  896 1529    4    1   97  402    2  380  295    3\n","  295   42  896   15 1529    4   26   15  370    4]\n"],"name":"stdout"}]},{"metadata":{"id":"XgcAwpfajPHk","colab_type":"code","colab":{}},"cell_type":"code","source":["embeddings_index = {}\n","f = open('/content/drive/My Drive/Colab Notebooks/glove.6B.50d.txt')\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    embeddings_index[word] = coefs\n","f.close()\n","\n","print('Found %s word vectors.' % len(embeddings_index))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QW4eAq3djcS3","colab_type":"code","colab":{}},"cell_type":"code","source":["EMBEDDING_DIM = 50\n","embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n","for word, i in word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        # words not found in embedding index will be all-zeros.\n","        embedding_matrix[i] = embedding_vector"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pxd071Fajm14","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.layers import Embedding\n","\n","embedding_layer = Embedding(len(word_index) + 1,\n","                            EMBEDDING_DIM,\n","                            weights=[embedding_matrix],\n","                            input_length=max_length_of_text,\n","                            trainable=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D2lon_tWj5iq","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.layers import Dense, Embedding, LSTM, Bidirectional\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","lstm_out =128\n","batch_size =16\n","inputs2 = Input((max_length_of_text, ))\n","x2 = embedding_layer(inputs2)\n","#x2=Bidirectional(LSTM(lstm_out = 128, dropout= 0.3, recurrent_dropout= 0.2))(x2)\n","x2= LSTM(128, dropout=0.3, recurrent_dropout=0.25, return_sequences=False)(x2)\n","x2=Dense(64,activation='relu')(x2)\n","x2=Dropout(0.3)(x2)\n","x2=Dense(4,activation='softmax')(x2)\n","model = Model(inputs2, x2)\n","print(model.summary())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JRPMnLlXrNdI","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install keras"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2VJuEBWmqz27","colab_type":"code","colab":{}},"cell_type":"code","source":["import keras\n","print(keras.__version__)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rDsCdrnX80sV","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"DnP1Y1vvKleU","colab_type":"code","colab":{}},"cell_type":"code","source":["from nltk.corpus import stopwords "],"execution_count":0,"outputs":[]},{"metadata":{"id":"npyGhD4ckUWf","colab_type":"code","colab":{}},"cell_type":"code","source":["model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tHorwLH6kcE2","colab_type":"code","colab":{}},"cell_type":"code","source":["filepath=r\"/content/drive/My Drive/Colab Notebooks/evaluation/ev_trial20.h5\"\n","\n","import keras\n","checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True,save_weights_only=False, mode='max')\n","\n","model.fit(X, y,validation_split=0.1, batch_size = batch_size, shuffle=True,epochs = 20,callbacks=[checkpoint])\n","model.save(r\"/content/drive/My Drive/Colab Notebooks/evaluation/project20.h5\")\n","with open(r\"/content/drive/My Drive/Colab Notebooks/evaluation/tokenizer.pickle\", 'wb') as handle:\n","    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6Ypc2C_ybM0P","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.models import load_model\n","model=load_model(r\"/content/drive/My Drive/Colab Notebooks/evaluation/.h5\")\n","score,acc = model.evaluate(X, y, batch_size = batch_size)\n","print(\"Score: %.2f\" % (score))\n","print(\"Validation Accuracy: %.2f\" % (acc))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rMGXeLZg07MI","colab_type":"code","colab":{}},"cell_type":"code","source":["new3=load_model(r\"/content/drive/My Drive/Colab Notebooks/evaluation/project13.h5\")\n","new3.summary()\n","new3.fit(X, y,validation_split=0.075, batch_size = batch_size, shuffle=True,epochs = 10,callbacks=[checkpoint])\n","new3.save(r\"/content/drive/My Drive/Colab Notebooks/evaluation/project13.h5\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LoYQCC4QvOvQ","colab_type":"code","colab":{}},"cell_type":"code","source":["new3=load_model(r\"/content/drive/My Drive/Colab Notebooks/evaluation/project13.h5\")\n","new3.summary()\n","new3.fit(X, y,validation_split=0.1, batch_size = batch_size, shuffle=True,epochs = 12,callbacks=[checkpoint])\n","new3.save(r\"/content/drive/My Drive/Colab Notebooks/evaluation/project13.h5\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"n_E8LaZbd4Wa","colab_type":"code","colab":{}},"cell_type":"code","source":["new3=load_model(r\"/content/drive/My Drive/Colab Notebooks/evaluation/project13.h5\")\n","new3.summary()\n","new3.fit(X, y,validation_split=0.1, batch_size = batch_size, shuffle=True,epochs = 5,callbacks=[checkpoint])\n","new3.save(r\"/content/drive/My Drive/Colab Notebooks/evaluation/project13.h5\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pef9qWsHfBo2","colab_type":"code","colab":{}},"cell_type":"code","source":["new3=load_model(r\"/content/drive/My Drive/Colab Notebooks/evaluation/project13.h5\")\n","new3.summary()\n","new3.fit(X, y,validation_split=0.1, batch_size = batch_size, shuffle=True,epochs = 5,callbacks=[checkpoint])\n","new3.save(r\"/content/drive/My Drive/Colab Notebooks/evaluation/project13.h5\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rF-QDCorf4sF","colab_type":"code","colab":{}},"cell_type":"code","source":["new3=load_model(r\"/content/drive/My Drive/Colab Notebooks/evaluation/project13.h5\")\n","new3.summary()\n","new3.fit(X, y,validation_split=0.1, batch_size = batch_size, shuffle=True,epochs = 5,callbacks=[checkpoint])\n","new3.save(r\"/content/drive/My Drive/Colab Notebooks/evaluation/project14.h5\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DiMWLOT7g6Va","colab_type":"code","colab":{}},"cell_type":"code","source":["new3=load_model(r\"/content/drive/My Drive/Colab Notebooks/evaluation/project14.h5\")\n","new3.summary()\n","new3.fit(X, y,validation_split=0.1, batch_size = batch_size, shuffle=True,epochs = 5,callbacks=[checkpoint])\n","new3.save(r\"/content/drive/My Drive/Colab Notebooks/evaluation/project15.h5\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"S655i3oljE0R","colab_type":"code","colab":{}},"cell_type":"code","source":["data2 = pd.read_csv('/content/drive/My Drive/Colab Notebooks/evaluation/test.csv')\n","pd.set_option('display.max_colwidth',-1)\n","data2.head()\n","tx2=data2['Scene'].values\n","y2=data['Sentiment'].values\n","print(tx2[1])\n","from nltk.corpus import stopwords \n","from nltk.tokenize import word_tokenize \n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","wordnet_lemmatizer = WordNetLemmatizer()\n","  \n","stop_words = set(stopwords.words('english')) \n","tx3=[]\n","for x in tx2:\n","  word_tokens = word_tokenize(x) \n","  \n","  filtered_sentence = [w for w in word_tokens if not w in stop_words] \n","  \n","  filtered_sentence = [] \n","  string=\"\"\n","  for w in word_tokens: \n","      if w not in stop_words: \n","          filtered_sentence.append(w) \n","  tx3.append(filtered_sentence)\n","print(tx3[2])\n","print(len(tx3))\n","#print(word_tokens) \n","#print(filtered_sentence)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mEuKQq1RlrPT","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.preprocessing import Normalizer\n","\n","num_words = 8000\n","tokenizer = Tokenizer(num_words=num_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\nÂ',\n","                                   lower=True,split=' ')\n","tokenizer.fit_on_texts(tx3)\n","X_test = tokenizer.texts_to_sequences(tx3)\n","print(len(X_test))\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index))\n","\n","max_length_of_text = 150\n","X_test =pad_sequences(X_test, maxlen=max_length_of_text)\n","print(len(X_test))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ELq-iQywX3B6","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.models import load_model\n","model=load_model(r\"/content/drive/My Drive/Colab Notebooks/evaluation/ev_trial13.h5\")\n","score,acc = model.evaluate(X_test, y, batch_size = batch_size)\n","print(\"Score: %.2f\" % (score))\n","print(\"Validation Accuracy: %.2f\" % (acc))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"d-rrk_qLiYmA","colab_type":"code","outputId":"f4d52957-6189-4fbb-ef6f-7a177731947e","executionInfo":{"status":"error","timestamp":1541012327137,"user_tz":-330,"elapsed":2239,"user":{"displayName":"Mayank Sharma","photoUrl":"","userId":"02640302405951026543"}},"colab":{"base_uri":"https://localhost:8080/","height":2359}},"cell_type":"code","source":["from keras.models import load_model\n","new=load_model(\"/content/drive/My Drive/Colab Notebooks/evaluation/project2.h5\")\n","new.summary()\n","array=[[]]\n","label=[]\n","#print(model.predict(X_test,batch_size = batch_size))\n","arr=new.predict(X_test,batch_size = batch_size)\n","i=0\n","dictionary = {'0' :'POSTIVE', '1':'NEUTRAL', '2':'NEGATIVE', '3':'MIXED'}\n","while i<len(X_test):\n","  g=np.argmax(arr[i])\n","  label.append(dictionary[str(g)])\n","  i=i+1\n","print(len(label))  \n","df = pd.DataFrame({\"Index\":[i+1 for i in range(len(label))],\"Sentiment\":label})\n","df.to_csv('/content/drive/My Drive/Colab Notebooks/evaluation/sol130.csv',index=False)\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-07ba3f7254d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Colab Notebooks/evaluation/project2.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    345\u001b[0m                         \u001b[0;34m'Maybe you meant to use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                         '`Sequential.from_config(config)`?')\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 return cls.from_config(config['config'],\n\u001b[1;32m    143\u001b[0m                                        custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 144\u001b[0;31m                                                            list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   2533\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mnode_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2535\u001b[0;31m                         \u001b[0mprocess_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mprocess_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m   2490\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2492\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2493\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2494\u001b[0m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[1;32m    591\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/embeddings.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             dtype=self.dtype)\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    414\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                             constraint=constraint)\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(value, dtype, name, constraint)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   def _variable_v2_call(cls,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m                         aggregation=VariableAggregation.NONE):\n\u001b[1;32m    124\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2442\u001b[0m         \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariable_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m         expected_shape=expected_shape, import_scope=import_scope)\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m           \u001b[0mexpected_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpected_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint)\u001b[0m\n\u001b[1;32m   1454\u001b[0m                 \u001b[0;34m\"construct, such as a loop or conditional. When creating a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m                 \u001b[0;34m\"variable inside a loop or conditional, use a lambda as the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1456\u001b[0;31m                 \"initializer.\" % name)\n\u001b[0m\u001b[1;32m   1457\u001b[0m           \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m           shape = (self._initial_value.get_shape()\n","\u001b[0;31mValueError\u001b[0m: Initializer for variable embedding_1/embeddings/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer."]}]},{"metadata":{"id":"-0k9Xu3Wd-LZ","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}